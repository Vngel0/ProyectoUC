---
title: "Taller 1 Regresión lineal"
author: "Angelo Inostroza - Christopher Recabarren"
output:
  html_document:
    theme: cosmo
    highlight: tango
    df_print: paged
---

```{r librerias, include = FALSE}
library(tidyverse)
library(janitor)
library(skimr)
library(stats)
library(GGally)
```

# Enunciado  
### Se le contratan sus servicios como Data Science en un centro meteorológico para poder crear un modelo que pueda estimar la diferencia de temperatura que habrá en un día (temperatura máxima menos la mínima), utilizando la información del día anterior, para ello se dispone de 40000 observaciones y un conjunto de 18 variables.

# Pregunta 1

>Cargue los datos lluvia.csv, verificando que estos hayan sido leídos correctamente, codifique como factor las variables que corresponda, además, generé un resumen exploratorio de los datos.

```{r ds lluvias, include = FALSE}
# Carga de datos con correcta lectura por formatos.
lluvia_original <- read.csv("Lluvia.csv", encoding = "utf-8")
```

#### Verificación de que los datos han sido cargados correctamente:

```{r head lluvias, echo = FALSE}
# Resumen exploratorio de los datos
head(lluvia_original)
```

#### Análisis exploratorio al dataset:

```{r fig.align="center", echo = FALSE}
# Resumen exploratorio de los datos
skim(lluvia_original)
```
#### Se logra apreciar que hay una variable que esta actuando como indice, la cual será removida pues no es relevante en el análisis.  

#### Notamos que existen ciertas variables que están como tipo número pero corresponden a variables de tipo factor, ya que, representan características de los datos, las cuales serán modificadas.  

#### Se observar un outlayer, pues el límite de nub3pm es hasta 8 y vemos un valor 9 el cual será eliminado, ya que, no tenemos certeza de cual es el valor que corresponde porque el máximo es otro. 

#### A continuación se detalla la fila a eliminar:

```{r outlayer, echo = FALSE}
outlayer <- lluvia_original %>% filter(Nub3pm == "9")

head(outlayer)

lluvia <- lluvia_original %>% filter(!Nub3pm == "9")
```

#### Datos limpios:

```{r Limpieza de datos, include = FALSE}
# Cambio a factor de variables y eliminación de x
lluvia <- lluvia %>% clean_names() %>%
  select(-x) %>% 
  mutate(koppen = as.factor(koppen),
         estacion = as.factor(estacion),
         lluvia_hoy = as.factor(lluvia_hoy))
```

#### Visualización general limpia:

```{r head limpio, echo = FALSE}
# Resumen exploratorio de los datos
head(lluvia)
```

#### Resumen exploratorio limpio:

```{r fig.align="center", echo = FALSE}
# Resumen exploratorio de los datos
skim(lluvia)
```

#### Tenemos 3 variables que han sido transformadas a factor (**koppen**, **estacion** y **lluvia_hoy**), el resto son númericas. 

#### Presentamos un outlayer en la variable **nub3pm** y no tenemos valores perdidos.

# Pregunta 2

>Para las variables continuas, genere un análisis gráfico de dichas variables con el target y un análisis de correlación lineal

#### Para realizar este análisis, consideraremos solo las variables continuas, excluyendo koppen, lluvia_hoy y estación porque corresponden variables categóricas/factor. Además,nub9am y nub3pm las dejaremos fuera de este análisis, ya que, si bien son numéricas, corresponde a una variable discreta.  


```{r fig.align="center", echo = FALSE, message = FALSE}
# Análisis de variables continuas con el target
g_hum3pm <- ggplot(data = lluvia, aes(y = target, x = hum3pm))+
  geom_point(color = 'Black', alpha = 0.5, shape = 18)+geom_smooth(color = 'steelblue')+
  theme_minimal()

g_hum9am <- ggplot(data = lluvia, aes(y = target, x = hum9am))+
  geom_point(color = 'Black', alpha = 0.5, shape = 18)+geom_smooth(color = 'steelblue')+
  theme_minimal()

g_lluvia <- ggplot(data = lluvia, aes(y = target, x = lluvia))+
  geom_point(color = 'Black', alpha = 0.5, shape = 18)+geom_smooth(color = 'steelblue')+
  theme_minimal()

g_pre3pm <- ggplot(data = lluvia, aes(y = target, x = pre3pm))+
  geom_point(color = 'Black', alpha = 0.5, shape = 18)+geom_smooth(color = 'steelblue')+
  theme_minimal()

g_pres9am <- ggplot(data = lluvia, aes(y = target, x = pres9am))+
  geom_point(color = 'Black', alpha = 0.5, shape = 18)+geom_smooth(color = 'steelblue')+
  theme_minimal()

g_sol <- ggplot(data = lluvia, aes(y = target, x = sol))+
  geom_point(color = 'Black', alpha = 0.5, shape = 18)+geom_smooth(color = 'steelblue')+
  theme_minimal()

g_temp3pm <- ggplot(data = lluvia, aes(y = target, x = temp3pm))+
  geom_point(color = 'Black', alpha = 0.5, shape = 18)+geom_smooth(color = 'steelblue')+
  theme_minimal()

g_temp9am <- ggplot(data = lluvia, aes(y = target, x = temp9am))+
  geom_point(color = 'Black', alpha = 0.5, shape = 18)+geom_smooth(color = 'steelblue')+
  theme_minimal()

g_evaporacion <- ggplot(data = lluvia, aes(y = target, x = evaporacion))+
  geom_point(color = 'Black', alpha = 0.5, shape = 18)+geom_smooth(color = 'steelblue')+
  theme_minimal()

g_vel3pm <- ggplot(data = lluvia, aes(y = target, x = vel3pm))+
  geom_point(color = 'Black', alpha = 0.5, shape = 18)+geom_smooth(color = 'steelblue')+
  theme_minimal()

g_vel_rafaga <- ggplot(data = lluvia, aes(y = target, x = vel_rafaga))+
  geom_point(color = 'Black', alpha = 0.5, shape = 18)+geom_smooth(color = 'steelblue')+
  theme_minimal()

g_vel9am <- ggplot(data = lluvia, aes(y = target, x = vel9am))+
  geom_point(color = 'Black', alpha = 0.5, shape = 18)+geom_smooth(color = 'steelblue')+
  theme_minimal()

gridExtra::grid.arrange(g_hum3pm,
                       g_hum9am,
                       g_lluvia,
                       g_pre3pm,
                       g_pres9am,
                       g_sol,
                       g_temp3pm,
                       g_temp9am,
                       g_evaporacion,
                       g_vel3pm,
                       g_vel_rafaga,
                       g_vel9am,
                       nrow = 3)

```
  

#### A partir de los gráficos anteriores, se logra verificar la correlación observada mencionada anteriormente, apreciamos que la linea de tendencia se ajusta a la relación entre las variables.  

<center>
```{r fig.align="center", echo = FALSE}
# Análisis de variables continuas con el target
variables_continuas <- lluvia %>% select(-koppen, -estacion, -lluvia_hoy, -nub3pm, -nub9am)
M <- cor(variables_continuas)
P <- ggcorrplot::cor_pmat(M)
ggcorrplot::ggcorrplot(M, lab = T, type="upper", digits = 1, p.mat = P,
                       ggtheme = ggplot2::theme_void,
                       title = "Correlación entre variables continuas")
```
</center>

#### Es posible observar que **target** tiene correlación con casi todas las variables.  
#### Sin embargo, las únicas que son significativas a partir de p-value son: **lluvia**, **hum9am**, **hum3pm**, **evaporacion**, **sol** y **temp3pm**, donde las más fuertes son **hum3pm** y la sigue **sol**.  

# Pregunta 3

>Realice un modelo de regresión lineal simple para modelar la diferencia de temperatura utilizando la covariable Temp3pm, además, generé el gráfico del target vs Temp3pm y añada la curva ajustada. ¿Es esta variable significativa?, ¿Cuál es la variabilidad explicada por el modelo?

```{r modelo regresion lineal simple, echo = FALSE}
# modelo de regresión lineal simple
modelo1 <- lm(target ~ temp3pm, data = lluvia)
summary(modelo1)
```

##### Según el modelo, es una variable significativa con 0.1% ***. Además este modelo explica el 20.36% de la variabiliadad.

```{r fig.align="center", echo = FALSE, message = FALSE}
# Gráfico
ggplot(data = lluvia, aes(y = target , x = temp3pm))+
  geom_point(color = 'Black', shape = 18, alpha = 0.5)+
  geom_smooth(method = "lm", se = F, color = 'steelblue')+
  theme_minimal()
```
 

# Pregunta 4

>Ajuste un modelo de regresión lineal utilizando la metodología forward y backward , ¿Los modelos obtenidos son diferentes?, ¿Son estos modelos significativos?, ¿Cuál es el porcentaje de variabilidad explicada por el mejor de estos modelos?

# ¿Los modelos obtenidos son diferentes?
```{r modelo regresion según metodología, include = FALSE, eval = TRUE}
# Modelo Regresión lineal
lm_null <- lm(target ~ 1, data = lluvia)
lm_all <- lm(target ~ ., data = lluvia)

lm_backward <- step(lm_all, direction = "backward")

lm_forward <- step(lm_null, formula(lm_all), direction = "forward")
```

```{r modelos obtenidos, echo = FALSE}
# Modelos

print(paste("Modelo Forward  : ", lm_forward$call[2]))
print(paste("Modelo Backward : ", lm_backward$call[2]))
```
#### Los modelos obtenidos, contienen las mismas variables, pero en diferente orden. Por lo tanto, son iguales. 

### Revisión del AIC
```{r AIC, echo = FALSE}

aic_forward <- data.frame(extractAIC(lm_forward))
a_f <- aic_forward[2,]

aic_backward <- data.frame(extractAIC(lm_backward))
a_b <- aic_backward[2,]

print(paste("AIC para Forward  : ", a_f))
print(paste("AIC para Backward : ", a_b))
```
#### El modelo Forward, es levemente mejor según el indicador AIC.

# ¿Son estos modelos significativos?  

```{r pvalue de los modelos, echo = FALSE}

print(paste("R cuadrado para Forward  : p-value < 2.2e-16"))
print(paste("R cuadrado para Backward : p-value < 2.2e-16"))
```
#### El valor p-values es menor a 0.05. Ambos modelos son significativos.

# ¿Cuál es el porcentaje de variabilidad explicada por el mejor de estos modelos?

```{r análisis de modelos, echo = FALSE}
# Análisis
#car::vif(lm_backward)
#car::vif(lm_forward)

print(paste("R cuadrado para Forward  : ", summary(lm_forward)$r.squared))
print(paste("R cuadrado para Backward : ", summary(lm_backward)$r.squared))

print(paste("R cuadrado ajustado para Forward  : ", summary(lm_forward)$adj.r.squared))
print(paste("R cuadrado ajustado para Backward : ", summary(lm_backward)$adj.r.squared))
```
#### Ambos modelos tienen un R cuadrado y R cuadrado ajustado sobre 78%. Explican de igual manera la variabilidad de los datos. Sin embargo, según el indicador AIC consideraremos mejor el modelo **forward**.

#### Modelo propuesto:
```{r modelo obtenidos, echo = FALSE}
print(lm_forward$call)
print(lm_forward$anova)

print(summary(lm_forward))
```
#### Podemos ver que el modelo es significativo, con un coeficiente de determinación sobre el 78%, considerándolo un modelo aceptable. Además todas las variables son significativas. 

# Pregunta 5
>Realice un estudio de residuos con los principales supuestos del mejor modelo de la pregunta 4, por medio de test estadísticos y gráficos. ¿Es un modelo adecuado?

#### Para analizar los residuos, verificaremos los supuestos de normalidad, homocedasticidad e independencia.

## Normalidad
```{r fig.align="center", echo = FALSE}
ggplot(lm_forward, aes(sample = lm_forward$residuals))+
  stat_qq(color = 'steelblue')+
  stat_qq_line()+
  theme_minimal()
```

#### Se observa que las puntas se alejan bastante de la recta, lo que nos permite concluir que no se cumple el supuesto de normalidad.

```{r supuesto normalidad, echo = FALSE}
nortest::lillie.test(lm_forward$residuals)
```
#### El valor p es bastante pequeño, por lo que se rechaza h0 confirmando lo anterior, no se cumple el supuesto de normalidad para los residuos.


## Homocedasticidad
```{r fig.align="center", echo = FALSE}
library(ggfortify)
autoplot(lm_forward, which = c(1,3), colour = "steelblue") + theme_minimal()
```
  

#### Observando de manera visual, se logra apreciar que la forma generada por los puntos no es constante, más bien similar a una circunferencia, por lo tanto, no se cumple el supuesto de homocedasticidad.

```{r supuesto homocedasticidad, echo = FALSE}
lmtest:: bptest(lm_forward)
```
#### El valor p es bastante pequeño, se rechaza h0 confirmando lo anterior, por lo tanto no  se cumple el supuesto de homocedásticidad en los residuos.

## Independencia
```{r supuesto autocorrelación, echo = FALSE}
lmtest::dwtest(lm_forward)
```
#### Aceptamos h0, dado que el valor p es mayor a 5%, por lo que los residuos no estan autocorrelacionados, lo que nos permite concluir que se cumple el supuesto de independencia.

# ¿Es un modelo adecuado?

#### A partir de lo mencionado anteriormente, tenemos estadísticos que avalan el modelo como el R cuadrado, el p value y todas las variables significativas.  
#### Ahora bien, luego de analizar los residuos, observando los supuestos se puede decir que el modelo no es aceptable, ya que, no cumple el test de normalidad ni homocedasticidad.  


# Pregunta 6

>Se dispone de un conjunto de datos Datos extras.csv en la cual se tiene información de 5000 tomas de muestras de una central meteorológica, utilizando el mejor modelo de la pregunta 4, generé la estimación de diferencias de temperaturas para dichas observaciones

```{r ds datos extra, include = FALSE}
# Carga de datos con correcta lectura por formatos.
datos_extra <- read.csv("Datos extras.csv", encoding = "utf-8")

datos_extra <- datos_extra %>% clean_names() %>%
  mutate(koppen = as.factor(koppen),
         estacion = as.factor(estacion),
         lluvia_hoy = as.factor(lluvia_hoy))         

datos_extra <- datos_extra %>% select(-x)
```


#### A continuación se visualizan los resultados de la predicción aplicando el modelo propuesto a los datos extras:
```{r estimación con el modelo, echo = FALSE}
prediccion <- predict(lm_forward, datos_extra)

head(prediccion, 8)

prediccion <- round(prediccion, 1) 

dato_extra <- datos_extra$target
```


#### Comparación entre la predicción del modelo y la información que trae datos extra:
```{r predicciones vs datos, echo = FALSE}
df <- prediccion

df <- cbind(prediccion, dato_extra)

head(df, 15)
```
